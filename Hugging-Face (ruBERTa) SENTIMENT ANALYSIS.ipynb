{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "519830c1",
   "metadata": {},
   "source": [
    "**SENTIMENT ANALYSIS:** \n",
    "\n",
    "\n",
    "**Using Hugging face ruBERta pretrained sentiment analysis Model to determine the emotions behind a tweet.**  \n",
    "**Ruberta was created by Meta Ai team**  \n",
    "**Based on the model, labels are - Negative , - Neutral , - Positive.**  \n",
    "**According to the  Hugging face website, the model has been trained on 58M tweets and proven to be accuarte.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f9fbd4",
   "metadata": {},
   "source": [
    "**INSTALLING THE NECESSARY PACKAGES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59e28358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install Transformer -- Transformer is used to download the model from the website \n",
    "# pip install Scipy -- Scipy will be used to convert the output into probabilty scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0f3b56",
   "metadata": {},
   "source": [
    "**IMPORTING THE NECESSARY LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23fb88b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e529317",
   "metadata": {},
   "source": [
    "**PREPROCESSING A TWEEET AND FITTING IT TO THE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af703ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '@user', '@user', '', 'both', 'can', 'suck', 'my', 'dick!', '#RT', '#LaurenBoebert', '#WorldCup2022', '\\n', '', '', '', '', '', '', '', '', '', '', '', '#ukrainecounteroffensive', 'http', '']\n"
     ]
    }
   ],
   "source": [
    "# A Tweet is usually inclusive of \n",
    "# - text e.g \"hey there!\"\n",
    "# - emoji e.g \"\"ðŸ˜Š\"\n",
    "# - url/link e.g http://google\n",
    "# - motion e.g @twitter \n",
    "\n",
    "# According to the website, the links/url in a tweet is represented with \"http\"\n",
    "# \" \" \" \" \" \" \" \" \" \" \"  \", the mentions(@) in a tweet i represented with \"@user\"  \n",
    "\n",
    "tweet = \"\"\" @realDonaldTrump @DonaldJTrumpJr  both can suck my dick! #RT #LaurenBoebert #WorldCup2022 \n",
    "            #ukrainecounteroffensive https://t.co/qVRtGje0DI \"\"\"\n",
    "\n",
    "tweet_words = [] # creating an empty list to append the preprocessed tweet into. \n",
    "\n",
    "for word in tweet.split(\" \"):\n",
    "    \n",
    "    if word.startswith(\"@\") and len(word)>1:\n",
    "        word = \"@user\" \n",
    "    \n",
    "    elif word.startswith(\"http\"):\n",
    "        word = \"http\"\n",
    "    \n",
    "    tweet_words.append(word)\n",
    "\n",
    "    \n",
    "print(tweet_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26978c5f",
   "metadata": {},
   "source": [
    "**JOINING THE PROCESSED TWEET WORDS BACK TOGETHER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b0a1e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " @user @user  both can suck my dick! #RT #LaurenBoebert #WorldCup2022 \n",
      "            #ukrainecounteroffensive http \n"
     ]
    }
   ],
   "source": [
    "tweet_processed = \" \".join(tweet_words)\n",
    "\n",
    "print(tweet_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d990e1cc",
   "metadata": {},
   "source": [
    "**LOADING THE RUBERTA - MODEL AND TOKENIZER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e061837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruberta_link = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "Model = AutoModelForSequenceClassification.from_pretrained(ruberta_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39f0ee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(ruberta_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b839e4e2",
   "metadata": {},
   "source": [
    "**LABELS:**  \n",
    "\n",
    "0 -> Negative  \n",
    "1 -> Neutral  \n",
    "2 -> Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cc7ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the labels list as classified in the model \n",
    "\n",
    "labels = [\"Negative\", \"Neutral\", \"Positive\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5ca504",
   "metadata": {},
   "source": [
    "**SENTIMENT ANALYSIS**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95fdeef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    0,   787, 12105,   787, 12105,  1437,   258,    64, 23829,   127,\n",
      "         38594,   328,   849, 13963,   849, 10766, 20732,   387,  3540,  6747,\n",
      "           849, 10988,   347,   658,   844,  2036,  1437, 50118,  1437,  1437,\n",
      "          1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,  1437,   849,\n",
      "          1350,  9946,  3204, 46014, 34361,  2054,  1437,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# Conveting the tweet to pytorch tensors to pass into the model \n",
    "\n",
    "encoded_tweet = tokenizer(tweet_processed,return_tensors='pt')\n",
    "\n",
    "print(encoded_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24af88e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[ 1.8780,  0.0334, -1.9883]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "# Passing the Encoded tweet inot the model for sentiment analysis \n",
    "\n",
    "output = Model(encoded_tweet['input_ids'],encoded_tweet['attention_mask'])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d150817",
   "metadata": {},
   "source": [
    "                                              OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47368edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[ 1.8780,  0.0334, -1.9883]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "# Unpacking the result of the encoded tweet and fitting it into the model \n",
    "\n",
    "output  = Model(**encoded_tweet)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70f5989",
   "metadata": {},
   "source": [
    "**CONVERTING THE OUT INTO PROBABILTY**  \n",
    "**USING SCIPY (Softmax) TO DETERMINE THE SENTIMENT/EMOTION BEHIND THE TEXT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61d5c17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.8780134   0.03339645 -1.9882714 ]\n"
     ]
    }
   ],
   "source": [
    "# Importing Numpy library to detach  and covert the result to array\n",
    "\n",
    "import numpy \n",
    "\n",
    "scores = output[0][0].detach().numpy()\n",
    "\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb6e03e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8481608  0.13408224 0.0177571 ]\n"
     ]
    }
   ],
   "source": [
    "# PAssing the score into sofmax to get the probabilty \n",
    "\n",
    "scores = softmax(scores)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2a395d",
   "metadata": {},
   "source": [
    "**Printing the Output with the Corresponding Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a668f4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative - 0.8481608\n",
      "Neutral - 0.13408224\n",
      "Positive - 0.017757103\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(scores)):\n",
    "    l = labels[i]\n",
    "    s = scores[i]    \n",
    "    print(l,\"-\",s)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96759808",
   "metadata": {},
   "source": [
    "**Thank You!**  \n",
    "**Olatunde**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
